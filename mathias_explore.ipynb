{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a8dad9a-d2b4-44c9-a677-32346b58f66b",
   "metadata": {},
   "source": [
    "Most forked Computational Neuroscience repositories as of May 12 2022 at 4:41 pm CST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584fd847-6568-40ed-972f-69220cc81f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871609ef-fa97-49cf-900d-aa77225cbfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnl = [\"NeuromatchAcademy/course-content\",\n",
    "\"asoplata/open-computational-neuroscience-resources\",\n",
    "\"translationalneuromodeling/tapas\",\n",
    "\"eselkin/awesome-computational-neuroscience\",\n",
    "\"computational-neuroscience/Computational-Neuroscience-UW\",\n",
    "\"neurolib-dev/neurolib\",\n",
    "\"simetenn/uncertainpy\",\n",
    "\"CompCogNeuro/sims\",\n",
    "\"compmem/compsy\",\n",
    "\"conorhoughton/COMS30127\",\n",
    "\"ashumeow/Computational-NeuroScience\",\n",
    "\"kuz/Computational-Neuroscience-Course\",\n",
    "\"INCF/neuroshapes\",\n",
    "\"CompCogNeuro/ed4\",\n",
    "\"alisharifi2000/CS-SBU-ComputationalNeuroScience2021-projects\",\n",
    "\"zifeo/EPFL\",\n",
    "\"robclewley/compneuro\",\n",
    "\"btel/python-in-neuroscience-tutorials\",\n",
    "\"neurodebian/neurodebian\",\n",
    "\"alfredcai/Coursera-Computational-NeuroScience\",\n",
    "\"neurodata/brainlit\",\n",
    "\"patrickmineault/xcorr-notebooks\",\n",
    "\"ITNG/ModelingNeuralDynamics\",\n",
    "\"neuronstar/spiking-neuron-models\",\n",
    "\"rougier/Neurosciences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138cba7d-aa2c-4afc-9250-0906e1f681be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d4ef518-0881-419d-b628-493da389b8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# NeuroMatch Academy (NMA) Computational Neuroscience syllabus\\n\\n**The content should primarily be accessed from our new ebook: https://compneuro.neuromatch.io/**\\n\\n**Objectives**: Introduce traditional and emerging computational neuroscience tools, their complementarity, and what they can tell us about the brain. A main focus is on modeling choices, model creation, model evaluation and understanding how they relate to biological questions.\\n\\n**Prerequisites**: [See here](https://github.com/NeuromatchAcademy/precourse)\\n\\n# Course materials\\n\\n- [Welcome Video](https://youtu.be/s4kBB1OMs0Q)\\n- [**Tutorials**: videos, notebooks, and slides](./tutorials/README.md)\\n- [**Projects**: videos, notebooks, and slides](./projects/README.md)\\n\\nGroup projects are offered for the *interactive track* only and will be running during all 3 weeks of NMA!\\n\\n# Course outline\\n\\n* Week 0 (Optional)\\n    * Asynchronous: Python Workshop Part 1 for students + Mandatory TA training for **ALL TAS**\\n    * Asynchronous: Python Workshop Part 2 for students + Mandatory TA training for **ALL TAS**\\n    * Wed, June 30th: Linear Algebra (Mandatory for all Tutorial TAs). Project TAs have separate training.\\n    * Thus, July 1st:Calculus (Mandatory for all Tutorial TAs). Project TAs have separate training.\\n    * Fri, July 2nd: Probability & Statistics (Mandatory for all Tutorial TAs). Project TAs have separate training.\\n\\n* Week 1\\n    * Mon, July 5: Model Types\\n    * Tue, July 6: Modeling Practice\\n    * Wed, July 7: Model Fitting\\n    * Thu, July 8: Generalized Linear Models\\n    * Fri, July 9: Dimensionality Reduction\\n\\n* Week 2\\n    * Mon, July 12: Deep Learning\\n    * Tue, July 13: Linear Systems\\n    * Wed, July 14: Biological Neuron Models\\n    * Thu, July 15: Dynamic Networks\\n    * Fri, July 16: Project day!\\n\\n* Week 3\\n    * Mon, July 19: Bayesian Decisions\\n    * Tue, July 20: Hidden Dynamics\\n    * Wed, July 21: Optimal Control\\n    * Thu, July 22: Reinforcement Learning\\n    * Fri, July 23: Network Causality\\n\\n\\n----\\n\\n# Daily schedule\\nAll days (except W1D2, W2D5, and W3D5) will follow this schedule for course time:\\n\\n|    Time (Hour)   |    Lecture                            |\\n|------------------|---------------------------------------|\\n|    0:00-0:30\\\\*   |    Intro video & text   |   \\n|    **0:30**-0:45**     |    Pod discussion I                   |                                      \\n|    0:45-2:15     |    Tutorials + nano-lectures I        |    \\n|    2:15-3:15     |    Big break                 |    \\n|    3:15-4:45     |    Tutorials + nano-lectures II      |   \\n|    4:45-4:55    |    Pod dicussion II       |    \\n|    4:55-5:00    |    Reflections & content checks               |    \\n|    5:05-5:35\\\\*     |    Outro                              |\\n\\n\\\\* The intro and outro will be watched asynchronously, which means that you can watch this lecture before and after the start of the synchronous session\\n\\n\\\\** Note that the synchronous session starts at 0:30 with the first pod discussion!\\n\\nOn W2D1, W2D4, and W3D4:\\n|    Time (Hour)   |    Lecture                            |\\n|------------------|---------------------------------------|\\n|    5:40-6:40     |    Live Q&A                                |   \\n\\n\\nOn W1D2 (project launch day):\\n\\n|    Time (Hour)   |    Lecture                            |\\n|------------------|---------------------------------------|\\n|    0:00-0:30\\\\*   |    Intro video & text   |   \\n|    **0:30**-2:30**     |    Tutorials + nano-lectures I                  |                                      \\n|    2:30-2:45     |    Outro           |\\n|    2:45-3:45     |    Big break                 |    \\n|    3:45-5:30     |    Literature review   |\\n|    5:30-5:45     |    Break     |\\n|    5:45-8:30***   |    Project proposal    |\\n\\n\\\\* The intro and outro will be watched asynchronously, which means that you can watch this lecture before and after the start of the synchronous session\\n\\n\\\\** Note that the synchronous session starts at 0:30 with the first pod discussion!\\n\\n\\\\*** Note that this includes the next available project time, which may be on the next day.\\n\\nOn W2D5 (abstract writing day):\\n\\n|    Time (Hour)   |    Lecture                            |\\n|------------------|---------------------------------------|\\n|  0:00-2:00\\\\*     |    Abstract workshop                  |\\n|  2:00-2:50     |    Big Break                              |\\n|  2:50-4:20     |    Individual abstract editing        |\\n|  4:20-5:05     |    Mentor meeting (flexible time)       |\\n|  5:05-5:25     |    Break                              |\\n|  5:25-6:25     |    Pod abstract swap                  |\\n|  6:25-8:00     |    Finalize abstract                  |\\n\\n* This day is completely asynchronous, so you should combine tutorial and project time for a total of 8 hours.\\n\\nOn W3D5 (final day!), we will have an extra celebration and pod wrap-ups after the material:\\n|    Time (Hour)   |    Lecture                            |\\n|------------------|---------------------------------------|\\n|    0:00-0:30\\\\*   |    Intro video & text   |   \\n|    **0:30**-0:45**     |    Pod discussion I                   |                                      \\n|    0:45-2:15     |    Tutorials + nano-lectures I        |    \\n|    2:15-3:15     |    Big break                 |    \\n|    3:15-4:45     |    Tutorials + nano-lectures II      |   \\n|    4:45-4:55    |    Pod dicussion II       |    \\n|    4:55-5:00    |    Reflections & content checks               |    \\n|    5:05-5:35\\\\*     |    Outro                              |\\n|    5:35-5:45     |    Break                        |\\n|    5:45-6:10    |    Evaluation report                      |\\n|    6:10-7:10    |    Project presentations                      |\\n|    7:10-7:25    |    Pod farewell                      |\\n|    7:25-8:15    |    Closing ceremony                      |\\n\\n\\\\* The intro and outro will be watched asynchronously, which means that you can watch this lecture before and after the start of the synchronous session\\n\\n\\\\** Note that the synchronous session starts at 0:30 with the first pod discussion!\\n\\n\\n\\n\\n\\n\\n\\n## Licensing\\n\\n[![CC BY 4.0][cc-by-image]][cc-by]\\n\\n[![CC BY 4.0][cc-by-shield]][cc-by] [![BSD-3][bsd-3-shield]][bsd-3]\\n\\nThe contents of this repository are shared under under a [Creative Commons Attribution 4.0 International License][cc-by].\\n\\nSoftware elements are additionally licensed under the [BSD (3-Clause) License][bsd-3].\\n\\nDerivative works may use the license that is more appropriate to the relevant context.\\n\\n[cc-by]: http://creativecommons.org/licenses/by/4.0/\\n[cc-by-image]: https://i.creativecommons.org/l/by/4.0/88x31.png\\n[cc-by-shield]: https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg\\n\\n[bsd-3]: https://opensource.org/licenses/BSD-3-Clause\\n[bsd-3-shield]: https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.readme_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46b2b0f-dae1-456d-9ced-a34d96cdb564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                  ==  ===============   === =\\n                           =  ================================\\n                      = ======= =        =  ==      ==============\\n                    ======                             = ============ = =\\n                ====== =                                  = ============ =\\n            = =======                                        = ============\\n          ===========                                             ==========\\n          ===== =                                                 = ==========\\n       ===== =                                                        ========\\n      ======                                                            ======\\n     =====                                           =                  =======\\n     ====                                            =                    ======\\n     ====                        ==   ==  =  == = ==                      ======\\n    =====                  = ======== =  ==   =                            ======\\n    ====              =  =====  ==                                         ======\\n    ===               ===== =                                               ======\\n    ===               ===                                                 =======\\n      =            = ==                                                 = ========\\n      =  =        =====                                             =============\\n                 =  ==                                        ==  =============\\n                 == ===                                 =   ================ =\\n                   =====                          == ================== ==\\n                  ==  ==== =                 =  ============ = ===  =\\n                       = ===== ===   ==  =============   == = =\\n                          = ====================   ==\\n\\n[NeuroDebian](http://neuro.debian.net) is a popular turnkey platform for\\nNeuroscience, where software is integrated, tested, and delivered\\nconveniently and reliably so you could concentrate on your research and\\nnot on \"system maintenance\".  It provides a large collection of popular\\nneuroscience research software for the Debian operating system as well\\nas Ubuntu and other derivatives.  Please visit our\\n[main website](http://neuro.debian.net) to discover more.\\n\\n[![Travis tests status](https://secure.travis-ci.org/neurodebian/neurodebian.png?branch=master)](https://travis-ci.org/neurodebian/neurodebian)\\n[![Docker](http://dockeri.co/image/_/neurodebian)](https://hub.docker.com/_/neurodebian/)\\n[![https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg](https://www.singularity-hub.org/static/img/hosted-singularity--hub-%23e32929.svg)](https://singularity-hub.org/collections/209)\\n\\n# Related projects from the NeuroDebian authors\\n\\n- [Open Brain Consent](http://open-brain-consent.readthedocs.io) - samples\\n  and an ultimate wording for experiment participant consent forms to make\\n  open data sharing possible\\n- [DataLad](http://datalad.org) - a data distribution and management\\n  platform, which addresses shortcomings of solutions of software/code-oriented\\n  solutions (such as NeuroDebian and pure git), when applied to data\\n- [ReproIn](http://reproin.repronim.org) - a turnkey solution for collecting\\n  MRI data directly as [BIDS](http://bids.neuroimaging.io) DataLad datasets\\n- [DueCredit](duecredit.org) - Automated collection and reporting of\\n  citations for used software/methods/datasets\\n- [Study Forrest](http://studyforrest.org) -  a diverse and\\n  ever-expanding collection of data and studies on our favorite shrimping,\\n  cross-country running, international ping-pong champion: *Forrest Gump*\\n- [PyMVPA](http://pymvpa.org) - a machine learning framework for the analysis\\n  of (not only) neuroimaging data\\n- Discover more about these and other projects from\\n  [Center for Open Neuroscience](http://centerforopenneuroscience.org) and\\n  [Psychoinformatics](http://psychoinformatics.de).\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.readme_contents[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786f2d9-9afb-4af0-bdbb-05395394bad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
